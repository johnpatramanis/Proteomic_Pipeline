#Run using snakemake -j1 --latency-wait 120 --use-conda


#Dependancies to be used 
#conda env export --from-history > environment.yaml
#conda env create --name testenv --file environment.yaml


import os
import os.path



##### Load Input Files and usefull info  #####


DATASETS={}
DATASETS_FILE=open('Datasets.txt','r')

Labels=DATASETS_FILE.readline()

for line in DATASETS_FILE:
    line=line.strip().split()
    Dataset=line[0]
    AncSamples=line[1].split(',')
    DATASETS[Dataset]=[x for x in AncSamples]
    
print(DATASETS)



#######################################################################################################################################################################
## Starting Rule

rule all:
    input:
        expand("{DATASETS}.info",DATASETS=DATASETS.keys())




#######################################################################################################################################################################
## Dataset Pipeline ##


#Organise Datasets
rule Organise_Data:
    input:
        "Datasets.txt"
    output:
        expand("{DATASETS}.info",DATASETS=DATASETS.keys())
    run:
        
        for DATASET,ANC_SAMPLES in DATASETS.items():
            print(DATASET,ANC_SAMPLES)
            shell("""echo '{}' >  Workspace/1_OG_Dataset/{}.info;""".format('\n'.join(ANC_SAMPLES),DATASET))
 